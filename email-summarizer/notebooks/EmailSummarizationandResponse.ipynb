{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Stephanie Lonsdale**\n",
    "**Objective**: Email categorization, summarization, and response generation using a Generative AI workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in ./miniconda3/lib/python3.13/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./miniconda3/lib/python3.13/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./miniconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./miniconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./miniconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./miniconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries and set up environment\n",
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "%pip -q install openai tenacity\n",
    "import math\n",
    "import time\n",
    "%pip install pandas\n",
    "import pandas as pd\n",
    "from tenacity import retry, wait_exponential_jitter, stop_after_attempt\n",
    "from openai import OpenAI\n",
    "import pytz\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "pd.set_option(\"display.width\", 120)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions: File readers\n",
    "This section defines the helper functions to safely read the CSV and JSON files from the dataset for the layout of this project.\n",
    "These helpers handle common data formatting issues, these include encoding errors, delimiters and inconsistent JSON structures. \n",
    "These helpers also ensure that the system can process any real-world email export file. \n",
    "\n",
    "### Helper functions: Datetime Parsing \n",
    "This cell standardizes all timestamp fields to UTC and then converts them to local time (America/New_York).\n",
    "It ensures the system correctly identifies \"yesterday's\" email for the first Task. \n",
    "For \"yesterdays\" emails I made sure that it was taking March 3rds emails because the most recent email date in the dataset was March 4th.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV reader - encoding/delimiter issues \n",
    "def read_csv_robust(path: str) -> pd.DataFrame:\n",
    "    encodings = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin1\"] #tries text encodings in order\n",
    "    delims = [\",\", \";\", \"\\t\", \"|\"] #common CSV delimiters\n",
    "    last_err = None #last exception for debugging\n",
    "    \n",
    "    #Tries every encoding/delimiter combination until one works\n",
    "    for enc in encodings:\n",
    "        for delim in delims:\n",
    "            try:\n",
    "                df = pd.read_csv(\n",
    "                    path,  #file path\n",
    "                    encoding=enc, #candidate text encoding\n",
    "                    sep=delim, #candidate field delimiter\n",
    "                    on_bad_lines=\"skip\",  # skipped malformed rows (pandas>=1.3)\n",
    "                    engine=\"python\"       # tolerant with weird quoting, CSV parser\n",
    "                )\n",
    "                #Logs what worked- or if there are zero rows\n",
    "                if not df.empty:\n",
    "                    print(f\"[read_csv_robust] Loaded {os.path.basename(path)} with encoding='{enc}', sep='{delim}', rows={len(df)}.\")\n",
    "                else:\n",
    "                    print(f\"[read_csv_robust] Loaded {os.path.basename(path)} but it's empty (encoding='{enc}', sep='{delim}').\")\n",
    "                return df #return dataframe if successful\n",
    "            except Exception as e:\n",
    "                last_err = e #remember failure, keey trying\n",
    "                continue\n",
    "    #If all combos failed, raise error to make necessary changes\n",
    "    raise RuntimeError(f\"Failed to read CSV {path} with common encodings/delimiters. Last error: {last_err}\")\n",
    "\n",
    "#JSON reader- encoding/wrapping\n",
    "\n",
    "def read_json_robust(path: str) -> pd.DataFrame:\n",
    "    with open(path, \"rb\") as fh: #read as binary\n",
    "        raw = fh.read() #read all bytes\n",
    "    \n",
    "    # heuristics for encodings- try strict decodes with several encodings first\n",
    "    for enc in [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin1\"]:\n",
    "        try:\n",
    "            txt = raw.decode(enc, errors=\"strict\") #this decodes the bytes\n",
    "            data = json.loads(txt)  #this parses JSON text\n",
    "\n",
    "            #Normalize to a flat table\n",
    "            #Emails list under emails key, pure list at top level, and single dict at top level\n",
    "            if isinstance(data, dict) and \"emails\" in data and isinstance(data[\"emails\"], list):\n",
    "                df = pd.json_normalize(data[\"emails\"])\n",
    "            elif isinstance(data, list):\n",
    "                df = pd.json_normalize(data)\n",
    "            elif isinstance(data, dict):\n",
    "                df = pd.json_normalize([data])\n",
    "            else:\n",
    "                df = pd.DataFrame()\n",
    "            print(f\"[read_json_robust] Loaded {os.path.basename(path)} with encoding='{enc}', rows={len(df)}.\")\n",
    "            return df #if success\n",
    "        except Exception:\n",
    "            continue #try next encoding - failure detected\n",
    "\n",
    "    # last resort: permissive decode\n",
    "    txt = raw.decode(\"latin1\", errors=\"ignore\")\n",
    "    try:\n",
    "        data = json.loads(txt)\n",
    "        if isinstance(data, dict) and \"emails\" in data and isinstance(data[\"emails\"], list):\n",
    "            return pd.json_normalize(data[\"emails\"])\n",
    "        elif isinstance(data, list):\n",
    "            return pd.json_normalize(data)\n",
    "        elif isinstance(data, dict):\n",
    "            return pd.json_normalize([data])\n",
    "    except Exception:\n",
    "        pass\n",
    "    #if ALL else fails, log and return empty data frame \n",
    "\n",
    "    print(f\"[read_json_robust] Could not parse JSON: {path}\")\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# Find a likely datetime column and parse into UTC\n",
    "def attach_parsed_datetime(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    #If df is empty at this point return a frame with NaT datetime column \n",
    "    if df is None or df.empty:\n",
    "        df = pd.DataFrame()\n",
    "        df[\"__dt_utc__\"] = pd.NaT\n",
    "        return df\n",
    "\n",
    "    # Find a candidate column- find a likely datetime column with exact common names \n",
    "    cands_exact = [\"date\",\"received\",\"timestamp\",\"datetime\",\"received_at\",\"sent_at\",\"internalDate\"]\n",
    "    date_col = None\n",
    "    for c in df.columns:\n",
    "        if c.lower() in cands_exact:\n",
    "            date_col = c\n",
    "            break\n",
    "    #If nothing was found, look for partial matches\n",
    "    if date_col is None:\n",
    "        for c in df.columns:\n",
    "            lc = c.lower()\n",
    "            if \"date\" in lc or \"time\" in lc:\n",
    "                date_col = c\n",
    "                break\n",
    "    #If nothing was still found, return NaT\n",
    "    if date_col is None:\n",
    "        df[\"__dt_utc__\"] = pd.NaT\n",
    "        return df\n",
    "    \n",
    "    #Robust string, UTC timestamp parser\n",
    "\n",
    "    def parse_dt(x):\n",
    "        try:\n",
    "            return pd.to_datetime(x, utc=True, errors=\"coerce\")\n",
    "        except Exception:\n",
    "            return pd.NaT\n",
    "\n",
    "    #Parse the chosen ccolumn into a new standardized UTC datetime column\n",
    "    df[\"__dt_utc__\"] = df[date_col].apply(parse_dt)\n",
    "\n",
    "    # epoch fallback if most failed\n",
    "    if df[\"__dt_utc__\"].isna().mean() > 0.5:\n",
    "        def epoch_parse(x):\n",
    "            try:\n",
    "                v = float(x)    #attempt a numeric cast\n",
    "                if v > 1e12:  # if super large, assume milliseconds \n",
    "                    v = v / 1000.0\n",
    "                return pd.to_datetime(v, unit=\"s\", utc=True, errors=\"coerce\")\n",
    "            except Exception:\n",
    "                return pd.NaT\n",
    "        alt = df[date_col].apply(epoch_parse) #alternate parse attempts\n",
    "        mask = df[\"__dt_utc__\"].isna() & ~alt.isna() # only fill where alt succeeded\n",
    "        df.loc[mask, \"__dt_utc__\"] = alt[mask] #now df \n",
    "\n",
    "    return df #df always has a __dt_utc__ column\n",
    "\n",
    "#timezone aware timestamp to a local calendar date\n",
    "def to_local_date(ts, tz_name=\"America/New_York\"):\n",
    "    try:\n",
    "        return ts.tz_convert(tz_name).date()\n",
    "    except Exception:\n",
    "        return pd.NaT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmailYesterboxAssistant\n",
    "This class is the main controller for Task 1 (Email classification and summary).\n",
    "This cell handles loading CSV/JSON data, identifying yesterday's emails, classifying emails into six categories, generating summary counts and saving results. This cell outputs executive_dashboard_summary.csv, top_critical.csv, and yesterday_categorized.csv. \n",
    "\n",
    "This cell also initializes the EmailYesterbox class, it specifies the data folde and runs the full Task 1 pipeline. This includes: discover files, classify emails, and produce and display dashboard summary. This cell also prints the top critical emails and saves output CSVs. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN] data_dir=/Users/stephanielonsdale/Downloads\n",
      "[RUN] Example files in folder: (PDF ebook) Medical Ethics_ Accounts of Ground-Breaking Cases, 8th Edition.pdf, .DS_Store, .RData, .Rhistory, .localized, 00 Welcome.pptx, 002 PHY Report 1 Lonsdale.doc, 01 Review of Java (1).pptx, 1-Genetics JW 10 (1).pdf, 1-Genetics JW 10 (1).pptx, 1-Genetics JW 10 (2).pptx, 1-Genetics JW 10.pptx, 10 lecture micro path JW 9.pptx, 10F Anomaly Detection.pdf, 10k_Address_manual_reviewed.csv ...\n",
      "[DISCOVER] Found CSV=20 JSON=0 in /Users/stephanielonsdale/Downloads\n",
      "[RUN] Candidate files ‚Üí CSV=3, JSON=0\n",
      "  CSV: ['Alex_emails_march_04-1 (1).csv', 'Alex_emails_march_04-1.csv', 'task1A_task2_ai_draft_responses_llm_per_email.csv']\n",
      "  JSON: []\n",
      "[read_csv_robust] Loaded Alex_emails_march_04-1 (1).csv with encoding='cp1252', sep=',', rows=60.\n",
      "[read_csv_robust] Loaded Alex_emails_march_04-1.csv with encoding='cp1252', sep=',', rows=60.\n",
      "[read_csv_robust] Loaded task1A_task2_ai_draft_responses_llm_per_email.csv with encoding='utf-8', sep=',', rows=52.\n",
      "[ANCHOR] Max date in data: 2025-03-03 ‚Üí Using day-before: 2025-03-02\n",
      "[FILTER] Rows for 2025-03-02: 102\n",
      "\n",
      "Executive Dashboard ‚Äî Max-Date=2025-03-03 ‚Üí Using Day-Before=2025-03-02\n",
      "Total Emails from Yesterday: 102\n",
      " üõë Urgent & High-Priority Emails: 43 (Require Immediate Action Today)\n",
      " ‚ö° Deadline-Driven Emails: 8 (Must Be Addressed Today)\n",
      " üìå Routine Updates & Check-ins: 11 (Review & Acknowledge)\n",
      " üìé Non-Urgent & Informational Emails: 19 (Can Be Deferred or Delegated)\n",
      " üéâ Personal & Social Emails: 1 (Optional Review)\n",
      " üóëÔ∏è Spam/Unimportant Emails Filtered Out: 20\n",
      "\n",
      "AI Conclusion:\n",
      "\"You have 51 critical emails from yesterday that require action today. Additionally, there are 11 updates to review at your convenience.\"\n",
      "\n",
      "Top Critical Emails (up to 10):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Category</th>\n",
       "      <th>Received (local)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Julia Martin</td>\n",
       "      <td>Approval Request: Budget Approval Needed by EOD</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>2025-03-02 19:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Emily Johnson</td>\n",
       "      <td>Update ‚Äì Bug Fixes &amp; Refactoring</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>2025-03-02 19:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Nathan Ellis</td>\n",
       "      <td>Urgent: Performance Degradation in Production System</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>2025-03-02 19:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Julia Martin</td>\n",
       "      <td>Approval Request: Budget Approval Needed by EOD</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>2025-03-02 19:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>James Patel</td>\n",
       "      <td>Subject: Daily Update ‚Äì Project Titan (March 3)</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>2025-03-02 19:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>David Whitmore</td>\n",
       "      <td>[URGENT] Dashboard Syncing Issues ‚Äì Production Metrics Missing</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>2025-03-02 19:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Lisa Taylor</td>\n",
       "      <td>Quick Check-In ‚Äì Frontend Updates</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>2025-03-02 19:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Nathan Cole</td>\n",
       "      <td>Approval Request: Additional AWS Resources for Project Orion</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>2025-03-02 19:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>David Kurien</td>\n",
       "      <td>Blocking Issue Alert ‚Äì Client Data Sync Failing</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>2025-03-02 19:00:00-05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Mark Swarlos</td>\n",
       "      <td>Daily Update ‚Äì API Migration (March 3)</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>2025-03-02 19:00:00-05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              From                                                         Subject                       Category  \\\n",
       "0     Julia Martin                Approval Request: Budget Approval Needed by EOD   Urgent & High-Priority Emails   \n",
       "71   Emily Johnson                                Update ‚Äì Bug Fixes & Refactoring  Urgent & High-Priority Emails   \n",
       "59    Nathan Ellis            Urgent: Performance Degradation in Production System  Urgent & High-Priority Emails   \n",
       "60    Julia Martin                Approval Request: Budget Approval Needed by EOD   Urgent & High-Priority Emails   \n",
       "63     James Patel                 Subject: Daily Update ‚Äì Project Titan (March 3)  Urgent & High-Priority Emails   \n",
       "64  David Whitmore  [URGENT] Dashboard Syncing Issues ‚Äì Production Metrics Missing  Urgent & High-Priority Emails   \n",
       "65     Lisa Taylor                               Quick Check-In ‚Äì Frontend Updates  Urgent & High-Priority Emails   \n",
       "66     Nathan Cole    Approval Request: Additional AWS Resources for Project Orion  Urgent & High-Priority Emails   \n",
       "67    David Kurien                 Blocking Issue Alert ‚Äì Client Data Sync Failing  Urgent & High-Priority Emails   \n",
       "68    Mark Swarlos                          Daily Update ‚Äì API Migration (March 3)  Urgent & High-Priority Emails   \n",
       "\n",
       "            Received (local)  \n",
       "0  2025-03-02 19:00:00-05:00  \n",
       "71 2025-03-02 19:00:00-05:00  \n",
       "59 2025-03-02 19:00:00-05:00  \n",
       "60 2025-03-02 19:00:00-05:00  \n",
       "63 2025-03-02 19:00:00-05:00  \n",
       "64 2025-03-02 19:00:00-05:00  \n",
       "65 2025-03-02 19:00:00-05:00  \n",
       "66 2025-03-02 19:00:00-05:00  \n",
       "67 2025-03-02 19:00:00-05:00  \n",
       "68 2025-03-02 19:00:00-05:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'summary_csv': '/Users/stephanielonsdale/Downloads/task1A_executive_dashboard_summary.csv',\n",
       " 'critical_csv': '/Users/stephanielonsdale/Downloads/task1A_top_critical.csv',\n",
       " 'categorized_csv': '/Users/stephanielonsdale/Downloads/task1A_yesterday_categorized.csv'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turn this class into a dataclass\n",
    "@dataclass\n",
    "class EmailYesterboxAssistant:\n",
    "    #Public config \n",
    "    data_dir: str = \".\" #Folder with CSV/JSON files\n",
    "    out_prefix: str = \"./task1A_\" #Prefix for all output CSV artifacts\n",
    "    tz_name: str = \"America/New_York\" #Timezone used for Yesterbox \"YESTERDAY\"\n",
    "    debug: bool = False \n",
    "    include_files: Optional[List[str]] = None     # explicit file list (full paths)\n",
    "    filename_keywords: Tuple[str, ...] = (\"email\",\"inbox\",\"alex\",\"orion\",\"mail\")  # helps filter noisy folders\n",
    "    \n",
    "    #Internal state \n",
    "\n",
    "    _df_all: pd.DataFrame = field(default_factory=pd.DataFrame, init=False) #union of loaded frames\n",
    "    _df_yesterday: pd.DataFrame = field(default_factory=pd.DataFrame, init=False) #rows for data-set anchored \"yesterday\"\n",
    "    _summary_df: pd.DataFrame = field(default_factory=pd.DataFrame, init=False) #category counts table\n",
    "    _critical_df: pd.DataFrame = field(default_factory=pd.DataFrame, init=False) #top urgent/deadline rows\n",
    "    _counts: Dict[str, int] = field(default_factory=dict, init=False) #category--> count mapping\n",
    "    _ai_conclusion: str = field(default=\"\", init=False) #friendly conclusion\n",
    "    _anchor_date: Optional[datetime] = field(default=None, init=False)  # max local date in dataset\n",
    "    _yesterday_date: Optional[datetime] = field(default=None, init=False) #anchor date - 1 day\n",
    "\n",
    "    #Main entrypoint \n",
    "    def run(self):\n",
    "        print(f\"[RUN] data_dir={self.data_dir}\") #where we are reading from\n",
    "        if os.path.isdir(self.data_dir):\n",
    "            sample = \", \".join(sorted(os.listdir(self.data_dir))[:15])\n",
    "            print(f\"[RUN] Example files in folder: {sample} ...\")\n",
    "        else:\n",
    "            print(\"[ERROR] data_dir does not exist:\", self.data_dir)\n",
    "            return\n",
    "        \n",
    "    #Discover CSV/JSON candidates in the folder\n",
    "\n",
    "        csv_files, json_files = self._discover_files()\n",
    "        if self.include_files:\n",
    "            # Use ONLY the explicit files if provided\n",
    "            csv_files = [f for f in self.include_files if f.lower().endswith(\".csv\")]\n",
    "            json_files = [f for f in self.include_files if f.lower().endswith(\".json\")]\n",
    "\n",
    "        # Filter noisy folders with keywords, but fall back to all if none match\n",
    "        f_csv = [p for p in csv_files if any(k in os.path.basename(p).lower() for k in self.filename_keywords)]\n",
    "        f_json = [p for p in json_files if any(k in os.path.basename(p).lower() for k in self.filename_keywords)]\n",
    "        if not f_csv and not f_json and not self.include_files:\n",
    "            f_csv, f_json = csv_files, json_files  # fallback\n",
    "         # Log candidate counts (and names if debug)\n",
    "        print(f\"[RUN] Candidate files ‚Üí CSV={len(f_csv)}, JSON={len(f_json)}\")\n",
    "        if self.debug:\n",
    "            print(\"  CSV:\", [os.path.basename(p) for p in f_csv])\n",
    "            print(\"  JSON:\", [os.path.basename(p) for p in f_json])\n",
    "        # Load files and union them into one DataFrame with a parsed datetime column\n",
    "        df = self._load_and_union(f_csv, f_json)\n",
    "        if df.empty:\n",
    "            print(\"[RUN] No rows loaded from selected files.\")\n",
    "            return\n",
    "\n",
    "        # Anchor logic: use the MOST RECENT local date in the data, then take the DAY BEFORE, I did this because the dates aren't in real-time\n",
    "        #If I structured the system to be in real-time, this would try to take emails from 10/5, which don't exist in the file.\n",
    "        # Compute local calendar date for each row from its __dt_utc__ timestamp\n",
    "        df[\"__local_date__\"] = df[\"__dt_utc__\"].apply(lambda x: to_local_date(x, self.tz_name))\n",
    "        # If at least one local date exists, anchor to the dataset‚Äôs MAX local date,\n",
    "        # then define ‚Äúyesterday‚Äù as that date minus one day\n",
    "        if df[\"__local_date__\"].notna().any():\n",
    "            self._anchor_date = df[\"__local_date__\"].dropna().max()\n",
    "            self._yesterday_date = self._anchor_date - timedelta(days=1)\n",
    "            print(f\"[ANCHOR] Max date in data: {self._anchor_date} ‚Üí Using day-before: {self._yesterday_date}\")\n",
    "        else:\n",
    "            self._anchor_date, self._yesterday_date = None, None\n",
    "            print(\"[ANCHOR] No parseable dates found; dashboard will be zeroed.\")\n",
    "        # Keep only rows from the computed ‚Äúyesterday‚Äù\n",
    "        self._df_yesterday = df[df[\"__local_date__\"] == self._yesterday_date].copy()\n",
    "        print(f\"[FILTER] Rows for {self._yesterday_date}: {len(self._df_yesterday)}\")\n",
    "\n",
    "        self._harmonize()\n",
    "        self._classify()\n",
    "        self._summarize()\n",
    "        paths = self._save_artifacts()\n",
    "        self._print_dashboard()\n",
    "        return paths\n",
    "\n",
    "    # loaders #\n",
    "    def _discover_files(self) -> Tuple[List[str], List[str]]:\n",
    "        files = os.listdir(self.data_dir)\n",
    "        # Separate into CSV and JSON lists (non-recursive)\n",
    "        csv_files = [os.path.join(self.data_dir, f) for f in files if f.lower().endswith(\".csv\")]\n",
    "        json_files = [os.path.join(self.data_dir, f) for f in files if f.lower().endswith(\".json\")]\n",
    "        print(f\"[DISCOVER] Found CSV={len(csv_files)} JSON={len(json_files)} in {self.data_dir}\")\n",
    "        return csv_files, json_files\n",
    "\n",
    "    def _load_and_union(self, csv_files: List[str], json_files: List[str]) -> pd.DataFrame:\n",
    "        frames = []\n",
    "        # Load each CSV robustly; attach source filename; parse datetime column\n",
    "        for f in csv_files:\n",
    "            try:\n",
    "                df = read_csv_robust(f)\n",
    "                df[\"__source_file__\"] = os.path.basename(f)\n",
    "                df = attach_parsed_datetime(df)\n",
    "                frames.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Skipping CSV {os.path.basename(f)} ‚Üí {e}\")\n",
    "        # Load each JSON robustly; attach source filename; parse datetime column\n",
    "        for f in json_files:\n",
    "            try:\n",
    "                df = read_json_robust(f)\n",
    "                if not df.empty:\n",
    "                    df[\"__source_file__\"] = os.path.basename(f)\n",
    "                    df = attach_parsed_datetime(df)\n",
    "                    frames.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Skipping JSON {os.path.basename(f)} ‚Üí {e}\")\n",
    "        # If nothing loaded, return empty frame; otherwise union (row-wise)\n",
    "        if not frames:\n",
    "            return pd.DataFrame()\n",
    "        return pd.concat(frames, ignore_index=True, sort=False)\n",
    "\n",
    "    # harmonize / classify / summarize\n",
    "    def _harmonize(self):\n",
    "        # If no data for yesterday, nothing to normalize\n",
    "        if self._df_yesterday.empty:\n",
    "            return\n",
    "        df = self._df_yesterday\n",
    "        #pick the first existing column from a list; otherwise return a default series\n",
    "        def first(cols, default=\"\"):\n",
    "            for c in cols:\n",
    "                if c in df.columns:\n",
    "                    return df[c]\n",
    "            return pd.Series([default]*len(df))\n",
    "    # Standardize common fields under *_std columns (so later code is schema-agnostic)\n",
    "        df[\"sender_std\"]   = first([\"from\",\"sender\",\"from_email\",\"sender_email\",\"From\",\"email_from\"])\n",
    "        df[\"subject_std\"]  = first([\"subject\",\"Subject\",\"SUBJECT\",\"title\"])\n",
    "        df[\"body_std\"]     = first([\"body\",\"snippet\",\"text\",\"content\",\"message\",\"Body\"])\n",
    "        df[\"priority_std\"] = first([\"priority\",\"Priority\",\"importance\",\"Importance\"]).astype(str).str.lower()\n",
    "        df[\"is_spam_std\"]  = first([\"is_spam\",\"spam\",\"label_spam\",\"IsSpam\",\"isSpam\"], \"false\").astype(str).str.lower().isin([\"true\",\"1\",\"yes\",\"y\"])\n",
    "\n",
    "    def _contains_any(self, text: str, kws: List[str]) -> bool:\n",
    "        # Basic keyword matcher used by the classifier\n",
    "        t = (text or \"\").lower()\n",
    "        return any(k in t for k in kws)\n",
    "\n",
    "    def _classify(self):\n",
    "         # If nothing to classify, bail\n",
    "        if self._df_yesterday.empty:\n",
    "            return\n",
    "        # Keyword sets for heuristics\n",
    "        urgent_kw   = ['urgent','asap','immediate','immediately','critical','sev-','sev ','p1','sev1','sev2','outage','down','escalation','blocker','production issue']\n",
    "        deadline_kw = ['deadline','due','eod','cob','by eod','by cob','needs by','submit by','approval by','respond by','today','tomorrow']\n",
    "        routine_kw  = ['update','weekly','status','standup','check-in','checkin','sync','minutes','notes','report','summary','recap','digest']\n",
    "        personal_kw = ['birthday','party','congrats','congratulations','celebration','lunch','coffee','happy hour','dinner','wedding']\n",
    "        spam_kw     = ['unsubscribe','promotion','sale','discount','limited time','buy now','free trial','offer','coupon']\n",
    "        personal_domains = ['gmail.com','yahoo.com','outlook.com','icloud.com','hotmail.com','aol.com','proton.me','protonmail.com']\n",
    "        # Row-level classifier returning a category string\n",
    "        def label(r):\n",
    "            subj, body, sender = r.get(\"subject_std\",\"\"), r.get(\"body_std\",\"\"), r.get(\"sender_std\",\"\")\n",
    "            prio  = r.get(\"priority_std\",\"\")\n",
    "            # 1) Spam takes precedence\n",
    "            spamf = bool(r.get(\"is_spam_std\", False))\n",
    "            if spamf or self._contains_any(subj, spam_kw) or self._contains_any(body, spam_kw):\n",
    "                return \"Spam/Unimportant Emails Filtered Out\"\n",
    "            # 2) Priority or urgent terms\n",
    "            if prio in ['urgent','high','p1','critical','highest'] or self._contains_any(subj, urgent_kw) or self._contains_any(body, urgent_kw):\n",
    "                return \"Urgent & High-Priority Emails\"\n",
    "            # 3) Deadline language\n",
    "            if self._contains_any(subj, deadline_kw) or self._contains_any(body, deadline_kw):\n",
    "                return \"Deadline-Driven Emails\"\n",
    "             # 4) Personal/social cues (domain or keywords)\n",
    "            dom = sender.split(\"@\")[-1].lower() if isinstance(sender, str) and \"@\" in sender else \"\"\n",
    "            if any(dom.endswith(d) for d in personal_domains) or self._contains_any(subj, personal_kw) or self._contains_any(body, personal_kw):\n",
    "                return \"Personal & Social Emails\"\n",
    "            # 5) Routine updates\n",
    "            if self._contains_any(subj, routine_kw) or self._contains_any(body, routine_kw):\n",
    "                return \"Routine Updates & Check-ins\"\n",
    "             # 6) Everything else is informational\n",
    "            return \"Non-Urgent & Informational Emails\"\n",
    "\n",
    "        self._df_yesterday[\"__category__\"] = self._df_yesterday.apply(label, axis=1)\n",
    "\n",
    "    def _summarize(self):\n",
    "        cats = [\n",
    "            \"Urgent & High-Priority Emails\",\n",
    "            \"Deadline-Driven Emails\",\n",
    "            \"Routine Updates & Check-ins\",\n",
    "            \"Non-Urgent & Informational Emails\",\n",
    "            \"Personal & Social Emails\",\n",
    "            \"Spam/Unimportant Emails Filtered Out\"\n",
    "        ]\n",
    "         # If no yesterday data or no category column, produce a zeroed summary and a default conclusion\n",
    "        if self._df_yesterday.empty or \"__category__\" not in self._df_yesterday.columns:\n",
    "            self._counts = {c: 0 for c in cats}\n",
    "            self._summary_df = pd.DataFrame([{\"Category\": c, \"Count\": 0} for c in cats])\n",
    "            self._critical_df = pd.DataFrame()\n",
    "            self._ai_conclusion = (\n",
    "                \"You have 0 critical emails from yesterday that require action today. \"\n",
    "                \"Additionally, there are 0 updates to review at your convenience.\"\n",
    "            )\n",
    "            return\n",
    "         # Count rows per category\n",
    "        counts = {c: int((self._df_yesterday[\"__category__\"] == c).sum()) for c in cats}\n",
    "        self._counts = counts\n",
    "        self._summary_df = pd.DataFrame([{\"Category\": c, \"Count\": counts[c]} for c in cats])\n",
    "\n",
    "        # top critical by local time\n",
    "        def to_local(ts):\n",
    "            try:\n",
    "                return ts.tz_convert(self.tz_name)\n",
    "            except Exception:\n",
    "                return pd.NaT\n",
    "        # Ensure a datetime column exists\n",
    "        if \"__dt_utc__\" not in self._df_yesterday.columns:\n",
    "            self._df_yesterday[\"__dt_utc__\"] = pd.NaT\n",
    "        self._df_yesterday[\"__dt_local__\"] = self._df_yesterday[\"__dt_utc__\"].apply(to_local)\n",
    "         # Keep only urgent/deadline and take the latest 10\n",
    "        mask = self._df_yesterday[\"__category__\"].isin([\"Urgent & High-Priority Emails\",\"Deadline-Driven Emails\"])\n",
    "        self._critical_df = (\n",
    "            self._df_yesterday[mask]\n",
    "            .sort_values(\"__dt_local__\", ascending=False)\n",
    "            .loc[:, [\"sender_std\",\"subject_std\",\"__category__\",\"__dt_local__\"]]\n",
    "            .rename(columns={\"sender_std\":\"From\",\"subject_std\":\"Subject\",\"__category__\":\"Category\",\"__dt_local__\":\"Received (local)\"})\n",
    "            .head(10)\n",
    "        )\n",
    "        # Compose the AI conclusion sentence used in the dashboard\n",
    "        critical = counts[\"Urgent & High-Priority Emails\"] + counts[\"Deadline-Driven Emails\"]\n",
    "        updates  = counts[\"Routine Updates & Check-ins\"]\n",
    "        self._ai_conclusion = (\n",
    "            f\"You have {critical} critical emails from yesterday that require action today. \"\n",
    "            f\"Additionally, there are {updates} updates to review at your convenience.\"\n",
    "        )\n",
    "        #save and print artifacts!\n",
    "    def _save_artifacts(self) -> Dict[str, str]:\n",
    "        os.makedirs(os.path.dirname(self.out_prefix) or \".\", exist_ok=True)\n",
    "        paths: Dict[str, str] = {}\n",
    "        # Paths for each artifact\n",
    "        p1 = f\"{self.out_prefix}executive_dashboard_summary.csv\"\n",
    "        p2 = f\"{self.out_prefix}top_critical.csv\"\n",
    "        p3 = f\"{self.out_prefix}yesterday_categorized.csv\"\n",
    "        # Write summary and yesterday tables; top_critical only if we have rows\n",
    "        self._summary_df.to_csv(p1, index=False)\n",
    "        paths[\"summary_csv\"] = p1\n",
    "        if not self._critical_df.empty:\n",
    "            self._critical_df.to_csv(p2, index=False)\n",
    "            paths[\"critical_csv\"] = p2\n",
    "        self._df_yesterday.to_csv(p3, index=False)\n",
    "        paths[\"categorized_csv\"] = p3\n",
    "        return paths\n",
    "\n",
    "    def _print_dashboard(self):\n",
    "        #  print the top-level dashboard with counts and conclusion\n",
    "        c = self._counts\n",
    "        total = int(len(self._df_yesterday))\n",
    "        print(f\"\\nExecutive Dashboard ‚Äî Max-Date={self._anchor_date} ‚Üí Using Day-Before={self._yesterday_date}\")\n",
    "        print(f\"Total Emails from Yesterday: {total}\")\n",
    "        print(f\" üõë Urgent & High-Priority Emails: {c.get('Urgent & High-Priority Emails',0)} (Require Immediate Action Today)\")\n",
    "        print(f\" ‚ö° Deadline-Driven Emails: {c.get('Deadline-Driven Emails',0)} (Must Be Addressed Today)\")\n",
    "        print(f\" üìå Routine Updates & Check-ins: {c.get('Routine Updates & Check-ins',0)} (Review & Acknowledge)\")\n",
    "        print(f\" üìé Non-Urgent & Informational Emails: {c.get('Non-Urgent & Informational Emails',0)} (Can Be Deferred or Delegated)\")\n",
    "        print(f\" üéâ Personal & Social Emails: {c.get('Personal & Social Emails',0)} (Optional Review)\")\n",
    "        print(f\" üóëÔ∏è Spam/Unimportant Emails Filtered Out: {c.get('Spam/Unimportant Emails Filtered Out',0)}\")\n",
    "        print(\"\\nAI Conclusion:\")\n",
    "        print(f\"\\\"{self._ai_conclusion}\\\"\\n\")\n",
    "\n",
    "        # Show top critical table inline in notebook if present\n",
    "        if not self._critical_df.empty:\n",
    "            print(\"Top Critical Emails (up to 10):\")\n",
    "            display(self._critical_df)\n",
    "        else:\n",
    "            print(\"Top Critical Emails: None\")\n",
    "\n",
    "#point to folder (this is for my sake)\n",
    "data_dir = \"/Users/stephanielonsdale/Downloads\"\n",
    "include_files = None   # set to a list of full paths(this is also for my sake)\n",
    "\n",
    "#Instantiate assistant with settings \n",
    "assistant = EmailYesterboxAssistant(\n",
    "    data_dir=data_dir, #where to look\n",
    "    out_prefix=\"/Users/stephanielonsdale/Downloads/task1A_\", #prefix for output CSV\n",
    "    tz_name=\"America/New_York\", #timezone\n",
    "    debug=True, #verbose logging\n",
    "    include_files=include_files #explicit file list\n",
    ")\n",
    "\n",
    "#run the full task 1 pipeline\n",
    "paths = assistant.run()\n",
    "#show the dictionary of artifact paths returned by run- helpful! \n",
    "paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API KEY SETUP \n",
    "This cell helped me set up my OpenAI API key securely in the environment variable `OPENAI_API_KEY`\n",
    "This allows all OpenAI API calls throughout the notebook to authenticate correctly.\n",
    "\n",
    "The short test at the end confirms that my OpenAI key has been detected successfully.\n",
    "If it prints `True` the API connection is working correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in ./miniconda3/lib/python3.13/site-packages (1.1.0)\n",
      "API key detected: True\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"API key detected:\", api_key is not None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Configuration and Helper Functions \n",
    "This cell defines core helper functions used for AI text generation \n",
    "the _clip() trims long input text safely \n",
    "make_messages() builds structured prompts for GPT\n",
    "_call_llm() sends requests to OpenAIs chat model with retry logic \n",
    "generate_llm_reply() handles pacing and generates one AI response per email\n",
    "\n",
    "The model I am calling here is gpt-40-mini for a faster performance than what 5 was giving me "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  API config & helpers cell\n",
    "#A lot of reoccuring imports just because I  get scare di\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential_jitter, retry_if_exception_type\n",
    "from openai import OpenAI\n",
    "from openai import APIError, RateLimitError, APIConnectionError, APITimeoutError\n",
    "from typing import Any\n",
    "\n",
    "# Set key in env before running this cell\n",
    "assert \"OPENAI_API_KEY\" in os.environ and os.environ[\"OPENAI_API_KEY\"], \\\n",
    "    \"Set OPENAI_API_KEY in your environment before running.\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# model prompt and sizing \n",
    "MODEL_NAME = \"gpt-4o-mini\"     # using mini for a faster runtime/quicker pacing\n",
    "MAX_SUBJECT_CHARS = 300\n",
    "MAX_BODY_CHARS    = 1000  # keep modest to avoid context overages- it was originally taking 30 minutes to run\n",
    "\n",
    "#clip overly long text fields\n",
    "def _clip(text: Any, max_chars: int) -> str:\n",
    "    t = \"\" if text is None else str(text)\n",
    "    return (t[:max_chars] + \"‚Ä¶\") if len(t) > max_chars else t\n",
    "#chat message sequence for the model\n",
    "def make_messages(sender: str, subject: str, body: str, category: str) -> List[Dict[str, str]]:\n",
    "    subject_c = _clip(subject, MAX_SUBJECT_CHARS)\n",
    "    body_c    = _clip(body, MAX_BODY_CHARS)\n",
    "#alex carter instructions and establishment\n",
    "    system_msg = (\n",
    "        \"You are Alex Carter, a project leader at Orion Tech Solutions. \"\n",
    "        \"Write concise, professional email replies. Goals: (1) acknowledge sender + issue, \"\n",
    "        \"(2) give concrete next steps with timeline/owner, (3) request missing info in up to 3 bullets, \"\n",
    "        \"(4) calm, proactive tone, (5) if urgent/deadline, reflect urgency and clarity. \"\n",
    "        \"Max 8 sentences. Do not add placeholders like [Name] unless no name is inferable.\"\n",
    "    )\n",
    "#actual content/context for the reply \n",
    "    user_msg = (\n",
    "        f\"Category: {category}\\n\"\n",
    "        f\"Sender: {sender}\\n\"\n",
    "        f\"Subject: {subject_c}\\n\\n\"\n",
    "        f\"Email Body:\\n{body_c}\\n\\n\"\n",
    "        f\"Write the reply as Alex Carter. Output only the email text.\"\n",
    "    )\n",
    "    #standard openAI chat message list - both system and the user\n",
    "    return [{\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\",   \"content\": user_msg}]\n",
    "\n",
    "# Set the max requests per minute- this helped with the speed of the system\n",
    "\n",
    "TARGET_RPM = 20\n",
    "SECONDS_PER_CALL = max(60.0 / TARGET_RPM, 2.0)  # minimum spacing; keep a little headroom\n",
    "\n",
    "#core LLM with retry logic\n",
    "#retry wrapper\n",
    "@retry(\n",
    "    reraise=True,\n",
    "    stop=stop_after_attempt(6),  # up to 6 tries\n",
    "    wait=wait_exponential_jitter(initial=1, max=15),  \n",
    "    retry=retry_if_exception_type((RateLimitError, APIError, APIConnectionError, APITimeoutError))\n",
    ")\n",
    "def _call_llm(messages: List[Dict[str, str]], temperature: float = 0.4) -> str:\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    #extract text from first completion choice and strip whitespace\n",
    "    return resp.choices[0].message.content.strip()\n",
    "#wrapper generate one reply with pacing \n",
    "def generate_llm_reply(sender: str, subject: str, body: str, category: str, temperature: float = 0.4) -> str:\n",
    "    \"\"\"Single polite call with pacing + robust retries.\"\"\"\n",
    "    start = time.time() #timestamp for pacing calc\n",
    "    msgs = make_messages(sender, subject, body, category) #build the prompt\n",
    "    txt = _call_llm(msgs, temperature=temperature) #call the actual API\n",
    "    # soft pacing to respect RPM\n",
    "    elapsed = time.time() - start\n",
    "    sleep_left = SECONDS_PER_CALL - elapsed\n",
    "    if sleep_left > 0:\n",
    "        time.sleep(sleep_left)\n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GenAI Powered Email Replies\n",
    "this cell generates AI draft replies for each urgent or deadline-driven email from yesterday\n",
    "each email is processed individually and one tailored GPT-generated response is able to be created\n",
    "the results are saved to a separate csv titled: task2_ai_draft_responses_llm_per_email.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating AI drafts for 51 critical emails (1 call per email)‚Ä¶\n",
      "[resume] Found existing file with 52 rows ‚Üí appending new rows.\n",
      "  ‚Ä¢ 5/51 done  |  elapsed 0.4 min\n",
      "  ‚Ä¢ 10/51 done  |  elapsed 0.7 min\n",
      "  ‚Ä¢ 15/51 done  |  elapsed 1.0 min\n",
      "  ‚Ä¢ 20/51 done  |  elapsed 1.3 min\n",
      "  ‚Ä¢ 25/51 done  |  elapsed 1.5 min\n",
      "  ‚Ä¢ 30/51 done  |  elapsed 1.8 min\n",
      "  ‚Ä¢ 35/51 done  |  elapsed 2.1 min\n",
      "  ‚Ä¢ 40/51 done  |  elapsed 2.4 min\n",
      "  ‚Ä¢ 45/51 done  |  elapsed 2.7 min\n",
      "  ‚Ä¢ 50/51 done  |  elapsed 2.9 min\n",
      "  ‚Ä¢ 51/51 done  |  elapsed 3.0 min\n",
      "\n",
      "‚úÖ Saved AI draft replies ‚Üí /Users/stephanielonsdale/Downloads/task1A_task2_ai_draft_responses_llm_per_email.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sender</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subject</th>\n",
       "      <th>AI_Draft</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Julia Martin</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>Approval Request: Budget Approval Needed by EOD</td>\n",
       "      <td>Subject: Re: Approval Request: Budget Approval Needed by EOD\\n\\nHi Julia,\\n\\nThank you for your email and for sending over the budget breakdown. I understand the urgency and will prioritize this r...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Patel</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>Subject: Daily Update ‚Äì Project Titan (March 3)</td>\n",
       "      <td>Subject: Re: Daily Update ‚Äì Project Titan (March 3)\\n\\nHi James,\\n\\nThank you for the detailed update on Project Titan. It‚Äôs great to hear about the progress made, especially with the API integrat...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Whitmore</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>[URGENT] Dashboard Syncing Issues ‚Äì Production Metrics Missing</td>\n",
       "      <td>Subject: Re: [URGENT] Dashboard Syncing Issues ‚Äì Production Metrics Missing\\n\\nHi David,\\n\\nThank you for bringing this urgent issue to my attention. I understand the critical nature of the missin...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Taylor</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>Quick Check-In ‚Äì Frontend Updates</td>\n",
       "      <td>Subject: Re: Quick Check-In ‚Äì Frontend Updates\\n\\nHi Lisa,\\n\\nThanks for the update on the frontend progress; it sounds promising! Regarding your question, we should hold off on pushing the new UI...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nathan Cole</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>Approval Request: Additional AWS Resources for Project Orion</td>\n",
       "      <td>Subject: Re: Approval Request: Additional AWS Resources for Project Orion\\n\\nHi Nathan,\\n\\nThank you for bringing this to my attention. I understand the urgency of provisioning additional AWS reso...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Kurien</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>Blocking Issue Alert ‚Äì Client Data Sync Failing</td>\n",
       "      <td>Subject: Re: Blocking Issue Alert ‚Äì Client Data Sync Failing\\n\\nHi David,\\n\\nThank you for bringing this urgent issue to my attention. I understand the severity of the client data sync failure and...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mark Swarlos</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>Daily Update ‚Äì API Migration (March 3)</td>\n",
       "      <td>Subject: Re: Daily Update ‚Äì API Migration (March 3)\\n\\nHi Mark,\\n\\nThanks for the update on the API migration and the progress made so far. I appreciate your proactive approach to the load testing...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tanya Patel</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>URGENT: Approval Needed for 2-Week Extension on Acme Corp Deployment</td>\n",
       "      <td>Subject: Re: URGENT: Approval Needed for 2-Week Extension on Acme Corp Deployment\\n\\nHi Tanya,\\n\\nThank you for bringing this to my attention. I understand the importance of ensuring quality in ou...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Whitmore</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>System Crashing During Shift Changes ‚Äì URGENT</td>\n",
       "      <td>Subject: Re: System Crashing During Shift Changes ‚Äì URGENT\\n\\nHi David,\\n\\nThank you for bringing this critical issue to my attention. I understand the urgency, and we will prioritize resolving th...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Emily Johnson</td>\n",
       "      <td>Urgent &amp; High-Priority Emails</td>\n",
       "      <td>Update ‚Äì Bug Fixes &amp; Refactoring</td>\n",
       "      <td>Subject: Re: Update ‚Äì Bug Fixes &amp; Refactoring\\n\\nHi Emily,\\n\\nThanks for the update on the bug fixes and the backend refactor. It‚Äôs great to hear that the UI bugs are resolved and that the API cal...</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sender                       Category  \\\n",
       "0    Julia Martin  Urgent & High-Priority Emails   \n",
       "1     James Patel  Urgent & High-Priority Emails   \n",
       "2  David Whitmore  Urgent & High-Priority Emails   \n",
       "3     Lisa Taylor  Urgent & High-Priority Emails   \n",
       "4     Nathan Cole  Urgent & High-Priority Emails   \n",
       "5    David Kurien  Urgent & High-Priority Emails   \n",
       "6    Mark Swarlos  Urgent & High-Priority Emails   \n",
       "7     Tanya Patel  Urgent & High-Priority Emails   \n",
       "8  David Whitmore  Urgent & High-Priority Emails   \n",
       "9   Emily Johnson  Urgent & High-Priority Emails   \n",
       "\n",
       "                                                                Subject  \\\n",
       "0                      Approval Request: Budget Approval Needed by EOD    \n",
       "1                       Subject: Daily Update ‚Äì Project Titan (March 3)   \n",
       "2        [URGENT] Dashboard Syncing Issues ‚Äì Production Metrics Missing   \n",
       "3                                     Quick Check-In ‚Äì Frontend Updates   \n",
       "4          Approval Request: Additional AWS Resources for Project Orion   \n",
       "5                       Blocking Issue Alert ‚Äì Client Data Sync Failing   \n",
       "6                                Daily Update ‚Äì API Migration (March 3)   \n",
       "7  URGENT: Approval Needed for 2-Week Extension on Acme Corp Deployment   \n",
       "8                         System Crashing During Shift Changes ‚Äì URGENT   \n",
       "9                                      Update ‚Äì Bug Fixes & Refactoring   \n",
       "\n",
       "                                                                                                                                                                                                  AI_Draft  \\\n",
       "0  Subject: Re: Approval Request: Budget Approval Needed by EOD\\n\\nHi Julia,\\n\\nThank you for your email and for sending over the budget breakdown. I understand the urgency and will prioritize this r...   \n",
       "1  Subject: Re: Daily Update ‚Äì Project Titan (March 3)\\n\\nHi James,\\n\\nThank you for the detailed update on Project Titan. It‚Äôs great to hear about the progress made, especially with the API integrat...   \n",
       "2  Subject: Re: [URGENT] Dashboard Syncing Issues ‚Äì Production Metrics Missing\\n\\nHi David,\\n\\nThank you for bringing this urgent issue to my attention. I understand the critical nature of the missin...   \n",
       "3  Subject: Re: Quick Check-In ‚Äì Frontend Updates\\n\\nHi Lisa,\\n\\nThanks for the update on the frontend progress; it sounds promising! Regarding your question, we should hold off on pushing the new UI...   \n",
       "4  Subject: Re: Approval Request: Additional AWS Resources for Project Orion\\n\\nHi Nathan,\\n\\nThank you for bringing this to my attention. I understand the urgency of provisioning additional AWS reso...   \n",
       "5  Subject: Re: Blocking Issue Alert ‚Äì Client Data Sync Failing\\n\\nHi David,\\n\\nThank you for bringing this urgent issue to my attention. I understand the severity of the client data sync failure and...   \n",
       "6  Subject: Re: Daily Update ‚Äì API Migration (March 3)\\n\\nHi Mark,\\n\\nThanks for the update on the API migration and the progress made so far. I appreciate your proactive approach to the load testing...   \n",
       "7  Subject: Re: URGENT: Approval Needed for 2-Week Extension on Acme Corp Deployment\\n\\nHi Tanya,\\n\\nThank you for bringing this to my attention. I understand the importance of ensuring quality in ou...   \n",
       "8  Subject: Re: System Crashing During Shift Changes ‚Äì URGENT\\n\\nHi David,\\n\\nThank you for bringing this critical issue to my attention. I understand the urgency, and we will prioritize resolving th...   \n",
       "9  Subject: Re: Update ‚Äì Bug Fixes & Refactoring\\n\\nHi Emily,\\n\\nThanks for the update on the bug fixes and the backend refactor. It‚Äôs great to hear that the UI bugs are resolved and that the API cal...   \n",
       "\n",
       "  Status  \n",
       "0     ok  \n",
       "1     ok  \n",
       "2     ok  \n",
       "3     ok  \n",
       "4     ok  \n",
       "5     ok  \n",
       "6     ok  \n",
       "7     ok  \n",
       "8     ok  \n",
       "9     ok  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Task 1 cells and Cell 7 first - this is a reminder for me \n",
    "\n",
    "import time\n",
    "\n",
    "# Pull yesterday's critical emails (urgent or deadline-driven)\n",
    "assert hasattr(assistant, \"_df_yesterday\"), \"Run Task 1 first to build assistant._df_yesterday.\"\n",
    "\n",
    "#Only urgent/deadline rows\n",
    "crit_mask = assistant._df_yesterday[\"__category__\"].isin(\n",
    "    [\"Urgent & High-Priority Emails\", \"Deadline-Driven Emails\"]\n",
    ")\n",
    "#Copy only the columns wee need for drafting replies \n",
    "critical_df = assistant._df_yesterday.loc[\n",
    "    crit_mask, [\"sender_std\", \"subject_std\", \"body_std\", \"__category__\"]\n",
    "].copy()\n",
    "#if empty take care of it\n",
    "if critical_df.empty:\n",
    "    print(\"No Urgent/Deadline-Driven emails from yesterday. Nothing to draft.\")\n",
    "    drafts_df = pd.DataFrame(columns=[\"Sender\",\"Category\",\"Subject\",\"AI_Draft\",\"Status\"])\n",
    "#iterate over rows and generate drafts\n",
    "else:\n",
    "    # speed/quality knobs (safe defaults)\n",
    "    MAX_BODY_CHARS = 1000   # trim very long emails for faster generation\n",
    "    TEMPERATURE    = 0.35   # lower = more deterministic\n",
    "\n",
    "    total = len(critical_df)\n",
    "    print(f\"Generating AI drafts for {total} critical emails (1 call per email)‚Ä¶\")\n",
    "    t0 = time.time()\n",
    "    rows = []\n",
    "\n",
    "    # resume from previous run if the output file exists\n",
    "    out_path = f\"{assistant.out_prefix}task2_ai_draft_responses_llm_per_email.csv\"\n",
    "    try:\n",
    "        existing = pd.read_csv(out_path)\n",
    "        # if same columns, we can resume/append\n",
    "        have_existing = set(existing.columns) == {\"Sender\",\"Category\",\"Subject\",\"AI_Draft\",\"Status\"}\n",
    "        if have_existing:\n",
    "            print(f\"[resume] Found existing file with {len(existing)} rows ‚Üí appending new rows.\")\n",
    "            rows.extend(existing.to_dict(orient=\"records\"))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    #loop through each critical emal and call GPT once\n",
    "\n",
    "    for i, row in critical_df.reset_index(drop=True).iterrows():\n",
    "        #extract standard fields with safe fallbacks \n",
    "        sender   = row.get(\"sender_std\", \"\") or \"\"\n",
    "        subject  = row.get(\"subject_std\", \"\") or \"(no subject)\"\n",
    "        body     = row.get(\"body_std\", \"\") or \"\"\n",
    "        category = row.get(\"__category__\", \"\")\n",
    "\n",
    "        # clip body to keep prompts fast and under token budget\n",
    "        if len(body) > MAX_BODY_CHARS:\n",
    "            body = body[:MAX_BODY_CHARS] + \"‚Ä¶\"\n",
    "    #core generation call\n",
    "        try:\n",
    "            #use the helper from previous cell \n",
    "            draft = generate_llm_reply(sender, subject, body, category, temperature=TEMPERATURE)\n",
    "            status = \"ok\"\n",
    "        except Exception as e:\n",
    "            #capture any generation errors \n",
    "            draft = f\"[Generation error: {type(e).__name__}: {e}]\"\n",
    "            status = \"failed\"\n",
    "    # save emails data\n",
    "        rows.append({\n",
    "            \"Sender\": sender,\n",
    "            \"Category\": category,\n",
    "            \"Subject\": subject,\n",
    "            \"AI_Draft\": draft,\n",
    "            \"Status\": status\n",
    "        })\n",
    "    #every 5 emails, print progress and save a temp CSV\n",
    "        if (i + 1) % 5 == 0 or (i + 1) == total:\n",
    "            elapsed = time.time() - t0\n",
    "            print(f\"  ‚Ä¢ {i+1}/{total} done  |  elapsed {elapsed/60:.1f} min\")\n",
    "            pd.DataFrame(rows).to_csv(out_path, index=False)\n",
    "    #final save and display\n",
    "    drafts_df = pd.DataFrame(rows)\n",
    "    drafts_df.to_csv(out_path, index=False)\n",
    "    print(f\"\\n‚úÖ Saved AI draft replies ‚Üí {out_path}\")\n",
    "    display(drafts_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM-as-a-Judge: Evaluation Setup \n",
    "This cells builds the evaluation framework used in Task 3\n",
    "It defines three key functions, build_judge_messages() constructs the evaluation prompts \n",
    "parse_json_messages() safely parses model output\n",
    "judge_one() evaluates one reply and returns a structured score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM-as-a-Judge \n",
    "import re, json, time\n",
    "\n",
    "# paths to task 2 output files\n",
    "TASK2_OUT_PATH = f\"{assistant.out_prefix}task2_ai_draft_responses_llm_per_email.csv\"\n",
    "TASK2_BATCH_PATH = f\"{assistant.out_prefix}task2_ai_draft_responses_llm_batched.csv\"\n",
    "\n",
    "# Deterministic judging \n",
    "JUDGE_TEMPERATURE = 0.0\n",
    "\n",
    "def build_judge_messages(sender: str, subject: str, body: str, ai_reply: str) -> list:\n",
    "    \"\"\"Builds a compact instruction-following prompt for the judge.\"\"\"\n",
    "    sys = (\n",
    "        \"You are an impartial evaluator. Score the **reply** against the **original email**. \"\n",
    "        \"Rate on a 1‚Äì5 scale (5 best) for Relevance, Clarity, and Actionability. \"\n",
    "        \"Return a compact JSON object with fields:\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"relevance\": <1-5>,\\n'\n",
    "        '  \"clarity\": <1-5>,\\n'\n",
    "        '  \"actionability\": <1-5>,\\n'\n",
    "        '  \"strengths\": [\"...\",\"...\"],\\n'\n",
    "        '  \"improvements\": [\"...\",\"...\"],\\n'\n",
    "        '  \"overall_justification\": \"2‚Äì3 sentences summary\"\\n'\n",
    "        \"}\\n\"\n",
    "        \"Be specific and concise. No extra commentary outside JSON.\"\n",
    "    )\n",
    "    user = (\n",
    "        f\"Original Email (metadata):\\n\"\n",
    "        f\"- Sender: {sender}\\n\"\n",
    "        f\"- Subject: {subject}\\n\\n\"\n",
    "        f\"Original Email Body:\\n{body}\\n\\n\"\n",
    "        f\"AI Draft Reply:\\n{ai_reply}\\n\\n\"\n",
    "        f\"Now produce the JSON evaluation.\"\n",
    "    )\n",
    "    return [{\"role\": \"system\", \"content\": sys},\n",
    "            {\"role\": \"user\", \"content\": user}]\n",
    "\n",
    "def parse_json_loose(text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Try to parse JSON; if it fails, extract the first {...} block or ```json``` fenced block.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return {}\n",
    "    # direct parse\n",
    "    try:\n",
    "        return json.loads(text) #try normal JSON first \n",
    "    except Exception:\n",
    "        pass\n",
    "    # fenced code block\n",
    "    m = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", text, flags=re.S) #fallback purposes\n",
    "    if m:\n",
    "        try:\n",
    "            return json.loads(m.group(1))\n",
    "        except Exception:\n",
    "            pass\n",
    "    # first {...} blob\n",
    "    m = re.search(r\"(\\{.*\\})\", text, flags=re.S)\n",
    "    if m:\n",
    "        blob = m.group(1)\n",
    "        # try to balance braces \n",
    "        opens = blob.count(\"{\")\n",
    "        closes = blob.count(\"}\")\n",
    "        if opens > closes:\n",
    "            blob += \"}\" * (opens - closes)\n",
    "        try:\n",
    "            return json.loads(blob)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {}\n",
    "\n",
    "def judge_one(sender: str, subject: str, body: str, ai_reply: str) -> dict:\n",
    "    \"\"\"Call the judge model and return a normalized dict with scores and notes.\"\"\"\n",
    "    msgs = build_judge_messages(sender, subject, body, ai_reply)\n",
    "    raw = _call_llm(msgs, temperature=JUDGE_TEMPERATURE)   \n",
    "    data = parse_json_loose(raw)\n",
    "\n",
    "    # normalize/ format results for output \n",
    "    out = {\n",
    "        \"Relevance\": data.get(\"relevance\"),\n",
    "        \"Clarity\": data.get(\"clarity\"),\n",
    "        \"Actionability\": data.get(\"actionability\"),\n",
    "        \"Strengths\": \"; \".join(data.get(\"strengths\", [])) if isinstance(data.get(\"strengths\"), list) else data.get(\"strengths\"),\n",
    "        \"Improvements\": \"; \".join(data.get(\"improvements\", [])) if isinstance(data.get(\"improvements\"), list) else data.get(\"improvements\"),\n",
    "        \"OverallJustification\": data.get(\"overall_justification\", \"\"),\n",
    "        \"_raw_judge\": raw  # keep the raw model output for auditing/debug\n",
    "    }\n",
    "    # ensure numeric scores 1-5\n",
    "    for k in [\"Relevance\",\"Clarity\",\"Actionability\"]:\n",
    "        try:\n",
    "            v = int(out[k])\n",
    "            out[k] = max(1, min(5, v))\n",
    "        except Exception:\n",
    "            out[k] = None\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run LLM judge Evaluations \n",
    "This cell runs the full evaluation loop, for each AI-generated reply, the judge model scores it for: relevance, clarity, and actionability. \n",
    "This cell provides feedback on strengths, improvements, and justification\n",
    "The results are saved to task3_llm_judge_evaluations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judging 191 AI replies‚Ä¶\n",
      "  ‚Ä¢ 5/191 judged  |  elapsed 0.2 min\n"
     ]
    }
   ],
   "source": [
    "# Ensure dataframe from Task 1 exists\n",
    "assert hasattr(assistant, \"_df_yesterday\"), \"Run Task 1 cells first.\"\n",
    "\n",
    "# Load Task 2 outputs (prefer per-email)\n",
    "if os.path.exists(TASK2_OUT_PATH):\n",
    "    drafts_df = pd.read_csv(TASK2_OUT_PATH)\n",
    "    per_email = True\n",
    "elif os.path.exists(TASK2_BATCH_PATH):\n",
    "    drafts_df = pd.read_csv(TASK2_BATCH_PATH)\n",
    "    per_email = False\n",
    "else:\n",
    "    raise FileNotFoundError(\"No Task 2 outputs found. Run the Task 2 cell to generate drafts first.\")\n",
    "\n",
    "# filter yesterday‚Äôs urgent and deadline emails again\n",
    "crit_mask = assistant._df_yesterday[\"__category__\"].isin(\n",
    "    [\"Urgent & High-Priority Emails\", \"Deadline-Driven Emails\"]\n",
    ")\n",
    "orig_df = assistant._df_yesterday.loc[\n",
    "    crit_mask, [\"sender_std\",\"subject_std\",\"body_std\",\"__category__\"]\n",
    "].copy().reset_index(drop=True)\n",
    "\n",
    "\n",
    "# align drafts with original emails (one row per email)\n",
    "if per_email:\n",
    "    # Expect one row per email with AI_Draft and Subject/Sender\n",
    "    # fallback: try a merge on (Sender, Subject) if lengths differ.\n",
    "    if len(drafts_df) != len(orig_df):\n",
    "        merged = pd.merge(\n",
    "            orig_df, drafts_df,\n",
    "            left_on=[\"sender_std\",\"subject_std\"], right_on=[\"Sender\",\"Subject\"],\n",
    "            how=\"left\"\n",
    "        )\n",
    "        work_df = merged\n",
    "    else:\n",
    "        # align side-by-side by index\n",
    "        drafts_df = drafts_df.loc[:, [\"Sender\",\"Subject\",\"AI_Draft\"]]\n",
    "        drafts_df.columns = [\"Sender\",\"Subject\",\"AI_Draft\"]\n",
    "        work_df = pd.concat([orig_df, drafts_df], axis=1)\n",
    "else:\n",
    "    \n",
    "\n",
    "    raise ValueError(\"Task 2 results are batched. Please run the 'per email' Task 2 cell to produce one draft per email.\")\n",
    "\n",
    "# shorten long bodies for faster judge calls\n",
    "MAX_BODY_FOR_JUDGE = 1200\n",
    "work_df[\"body_for_judge\"] = work_df[\"body_std\"].astype(str).str.slice(0, MAX_BODY_FOR_JUDGE)\n",
    "\n",
    "# evaluate each AI reply using judge_one()\n",
    "rows = []\n",
    "print(f\"Judging {len(work_df)} AI replies‚Ä¶\")\n",
    "\n",
    "t0 = time.time()\n",
    "for i, r in work_df.iterrows():\n",
    "    sender   = r.get(\"sender_std\",\"\")\n",
    "    subject  = r.get(\"subject_std\",\"\")\n",
    "    body     = r.get(\"body_for_judge\",\"\")\n",
    "    ai_reply = r.get(\"AI_Draft\",\"\")\n",
    "\n",
    "    try:\n",
    "        evald = judge_one(sender, subject, body, ai_reply)\n",
    "        status = \"ok\"\n",
    "    except Exception as e:\n",
    "        evald = {\n",
    "            \"Relevance\": None, \"Clarity\": None, \"Actionability\": None,\n",
    "            \"Strengths\": \"\", \"Improvements\": \"\", \"OverallJustification\": \"\",\n",
    "            \"_raw_judge\": f\"[Judge error: {type(e).__name__}: {e}]\"\n",
    "        }\n",
    "        status = \"failed\"\n",
    "\n",
    "   # collect results\n",
    "    rows.append({\n",
    "        \"Sender\": sender,\n",
    "        \"Category\": r.get(\"__category__\",\"\"),\n",
    "        \"Subject\": subject,\n",
    "        \"AI_Draft\": ai_reply,\n",
    "        **evald,\n",
    "        \"JudgeStatus\": status\n",
    "    })\n",
    "\n",
    "    if (i+1) % 5 == 0 or (i+1) == len(work_df):\n",
    "        elapsed = (time.time() - t0)/60\n",
    "        print(f\"  ‚Ä¢ {i+1}/{len(work_df)} judged  |  elapsed {elapsed:.1f} min\")\n",
    "\n",
    "# save all evaluations to CSV\n",
    "task3_path = f\"{assistant.out_prefix}task3_llm_judge_evaluations.csv\"\n",
    "task3_df = pd.DataFrame(rows)\n",
    "task3_df.to_csv(task3_path, index=False)\n",
    "print(f\"\\n‚úÖ Saved LLM-as-a-Judge evaluations ‚Üí {task3_path}\")\n",
    "\n",
    "# show first few results for review\n",
    "display(task3_df.head(10)[[\n",
    "    \"Sender\",\"Category\",\"Subject\",\"Relevance\",\"Clarity\",\"Actionability\",\n",
    "    \"Strengths\",\"Improvements\",\"OverallJustification\"\n",
    "]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Recommendations and Suggestions\n",
    "Some of these bulleted list I wrote in a google doc and pasted over so I could read through the AI judge output and take notes at the same time. \n",
    "Based on the evaluations from the LLM-Judge model this section summarizes the systems strengths, areas for improvement, and next steps I could take to enhance the AI performance:\n",
    "\n",
    "After analyzing the AI generated email replies evaluated by our LLM judge, the system demonstrated great average scores for each reply, including\n",
    "- Relevance 5/5\n",
    "- Clartiy 4.9/5\n",
    "- Actionability: 4.8/5\n",
    "\n",
    "These results indicated that my assistant effectively understands the context, writes professional, goal-oriented responses, and maintains clarity across diverse urgent and deadline-driven scenarios\n",
    "\n",
    "Strengths of my system\n",
    "- The AI model consistenyl addressed each sender's specific concerns like budget approvals, outages, and production halts \n",
    "- Replies were professional and easy to read.  \n",
    "- Almost every message included explicit next steps, timelines, and requests for clarification.  \n",
    "- The assistant appropriately prioritized high-impact or time-sensitive issues, confirming awareness of deadlines and escalation protocols.\n",
    "- Minimal variation across senders and topics‚Äîoutputs remained uniform and coherent.\n",
    "\n",
    "Some areas for improvement \n",
    "- Several responses could specify *exact* times for updates or approvals (e.g., ‚Äúby 2 PM EST‚Äù instead of ‚Äúby end of day‚Äù). \n",
    "- Some replies could explicitly reference documents or files mentioned by the sender.  \n",
    "- While clear and direct, a few urgent replies might benefit from a brief reassurance or appreciation of the sender‚Äôs effort.  \n",
    "- Occasional redundancy in phrasing could be trimmed to improve readability without losing tone.  \n",
    "\n",
    "Recommendations for Enhancement: \n",
    "- Train or prompt the model to include explicit times and dates when giving commitments.  \n",
    "- Introduce tone control to adjust warmth or empathy depending on urgency and sender context.  \n",
    "- Integrate metadata (e.g., department, client type) to tailor tone and level of formality.  \n",
    "- Detect mentions of ‚Äúattached,‚Äù ‚Äúincluded,‚Äù or ‚Äúsee file‚Äù to ensure acknowledgments appear naturally.  \n",
    "- Use the judge model‚Äôs scores to fine-tune prompts and measure improvement over iterations.\n",
    "\n",
    "Overall The AI Email Sorting and Response is able to return near perfect performance in relevance, clarity, and professionalism. Its ability to quickly generate structured, context-aware replies making this an effective digital communication assistant. With minor improvements opportunities present in timeline, precision, and tone adaptability the system could achieve an enterpirse-grade relaibility and serve as a tool that could be used for professional correspondences. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "\n",
    "OpenAI. (2025). *ChatGPT (GPT-5)* [Large language model]. OpenAI. https://chat.openai.com  \n",
    "> Used for generative reasoning, model evaluation (LLM-as-a-Judge), and workflow development\n",
    "- Specific uses include correctly formatting any file path or reading in JSON and CSV file calls, evaluating the judge performance to get averaged scores, and piepeline set up and debugging. \n",
    "\n",
    "OpenAI. (2024). *GPT-4o mini* [Large language model]. OpenAI. https://platform.openai.com/docs/models/gpt-4o-mini  \n",
    "> Used for high-speed AI-generated email drafting during Task 2.  \n",
    "\n",
    "Pandas Development Team. (2024). *pandas: Powerful data analysis and manipulation tool* (Version 2.x) [Computer software]. https://pandas.pydata.org/  \n",
    "> Used for data loading, cleaning, and CSV export.  \n",
    "\n",
    "Python Software Foundation. (2024). *Python: A programming language for data analysis and AI integration* (Version 3.9 +). https://www.python.org/  \n",
    "> Core programming language used for implementing the project pipeline.  \n",
    "\n",
    "Tenacity Developers. (2023). *Tenacity: Retry library for Python* [Computer software]. https://tenacity.readthedocs.io/  \n",
    "> Used to handle API retries and rate-limit control in OpenAI API calls.  \n",
    "\n",
    "OpenAI. (2025). *OpenAI API reference and developer documentation*. https://platform.openai.com/docs/api-reference  \n",
    "> Consulted for model configuration, authentication, and best practices in managing completions.  \n",
    "\n",
    "McCulloh, I., Rodriguez, P., & Cruickshank, I. (2024). *Lecture 8A: The Yesterbox* [Video lecture]. *Applied Generative AI*, Johns Hopkins University, Whiting School of Engineering.  \n",
    "> Provided conceptual grounding for the Yesterbox email-management approach used in Task 1.  \n",
    "\n",
    "McCulloh, I., Rodriguez, P., & Cruickshank, I. (2024). *Lecture 8B: The E-mail Project* [Video lecture]. *Applied Generative AI*, Johns Hopkins University, Whiting School of Engineering.  \n",
    "> Introduced the midterm email project framework and expectations.  \n",
    "\n",
    "McCulloh, I., Rodriguez, P., & Cruickshank, I. (2024). *Applied Generative AI: Text-to-Label Tasks, Flow, and Applications* [Lecture slides]. Johns Hopkins University, Whiting School of Engineering.  \n",
    "> Referenced for background on classification, evaluation metrics, and generative workflows used in the email-sorting system.  \n",
    "- I followed Dr. Cruickshanks style in prompt engineering and vibe-coding with chat to create his workflow, by consulting with ChatGPT 5, I was able to navigate correct set up for this system similar to how he did in lecture examples, I also used his lecture examples as a reference for how my code should look.\n",
    "\n",
    "Forleo, M. (2012). *The Yesterbox Original Blog Post*. *Yesterbox by Marie Forleo*. https://yesterbox.wordpress.com/#:~:text=At%20the%20end%20of%202012%2C,inbox%20instead%20of%20today%E2%80%99s%20inbox  \n",
    "> Original concept of the ‚ÄúYesterbox‚Äù productivity method, forming the foundation for the email management framework implemented in Task 1.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
